os: linux
dist: trusty

language: python

cache:
  directories:
    - $HOME/.cache/spark-versions

env:
  global:
    - HYPEROPT_FMIN_SEED=3
    - SPARK_VERSION=2.4.4
    - SPARK_BUILD="spark-${SPARK_VERSION}-bin-hadoop2.7"
    - SPARK_BUILD_URL="https://archive.apache.org/dist/spark/spark-${SPARK_VERSION}/${SPARK_BUILD}.tgz"
    - SPARK_HOME=$HOME/.cache/spark-versions/${SPARK_BUILD}
    - RUN_ONLY_LIGHT_TESTS=True
    - NUMPY_VERSION=1.14.3
jobs:
  include:
    - python: 2.7
      env:
        - IPYTHON="ipython[all]==5.4.1"
    - python: 3.5
      env:
        - IPYTHON=ipython[all]
    - python: 3.6
      env:
        - IPYTHON=ipython[all]
    #- python: 3.7
    #  dist: xenial
    #  env:
    #    - IPYTHON=ipython[all]
    #    - NUMPY_VERSION=1.19.0
    - python: 3.8
      dist: xenial
      env:
        - IPYTHON=ipython[all]
        - NUMPY_VERSION=1.19.0

services:
  - mongodb

before_script:
  - sleep 15 # mongo takes time to start
  - mongo mydb_test --eval 'db.createUser({user:"travis",pwd:"test",roles:["readWrite"]});'

before_install:
  - ./download_spark_dependencies.sh

install:
  - sudo apt-get remove ipython
  - pip install --upgrade pip
  - pip install --upgrade setuptools
  - pip install --upgrade wheel
  - pip install $IPYTHON
  - pip install --only-binary=numpy,scipy numpy==$NUMPY_VERSION scipy
  - pip install .[MongoTrials]
  - pip install .[SparkTrials]
  - pip install .[ATPE]
  - pip install pytest>=3.6
  - pip install pytest-cov pep8 pytest-pep8
  - pip install wrapt
script:
  - ./run_tests.sh
after_success:
  - coveralls
